{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e3fcf7c-e9ec-4fd2-98a5-04d5534251fa",
   "metadata": {},
   "source": [
    "<b> Title: </b> Group 11 Final Project Report - DSCI 100 002 \n",
    "\n",
    "<b> Group members: </b> Katie Archer, Noor Naila Imtinan Himam, Matthew Yeung, Wenwen Zhao"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b692e83d-b171-416f-bad7-d00f894b36c9",
   "metadata": {},
   "source": [
    "<b>1. Introduction</b>\n",
    "<br>\n",
    "According to scientific research, pulsars are an uncommon form of neutron stars that emit regular pulses of radiation, varying from several seconds to milliseconds in frequency. The potent magnetic fields of these stars generate intense beams of light at both poles. These beams are periodically observed as the pulsar rotates quickly, and they can only be observed with large telescopes when they cross our line of sight from Earth (National Aeronautics and Space Administration, n.d.)\n",
    "\n",
    "Although pulsars emit a pattern of radio emission that can be detected as they rotate, it can be challenging to distinguish between genuine signals and background noise. Pulsar candidates are being classified as binary classification issues using machine learning tools. The HTRU 2 dataset, which is used to train classification models, includes examples of both real and fake pulsar signals. The class labels used are 0 (negative) and 1 (positive), with the legitimate pulsar examples being the minority positive class. The eight continuous variables are obtained from the integrated pulse profile and the DM-SNR (Disperion Measure-Signal-to-Noise Ratio) curve, which describes the longitude-resolved version of the signal averaged in both time and frequency (Keith et al., 2010). Each candidate in the dataset is described by eight continuous variables, one class variable, and no astronomical information. The integrated pulse profile and the DM-SNR curve are used to determine the eight variables.\n",
    "\n",
    "In this project, we aim to produce a KNN classification model from the integrated pulse profile and DM-SNR curve of pulsar candidates to classify whether signals are legitimate or spurious (real or fake pulsar). The data will be used to explore the correlation between two variables, the class imbalance and the combination of predictors that would create a model with the greatest accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c4c763-a084-475b-b915-8832b6234d1b",
   "metadata": {},
   "source": [
    "<b>2. Preliminary exploratory data analysis:</b>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4b953b-9773-4582-8247-c17372463d1c",
   "metadata": {},
   "source": [
    "First, we load all of the libraries that we will need for the remainder of this project. This includes installing a package that will allow us to upsample our dataset later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f97abf-d9bd-4147-95b2-c1a0c8da1e41",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#CAUTION: Takes a long time to load.\n",
    "install.packages(\"themis\")\n",
    "install.packages(\"tidymodels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe00850e-2b65-4da2-96e2-08ae49344ad4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "library(tidyverse)\n",
    "library(repr)\n",
    "library(tidymodels)\n",
    "library(dplyr)\n",
    "library(ggplot2)\n",
    "library(GGally)\n",
    "install.packages(\"corrplot\")\n",
    "library(corrplot)\n",
    "library(RColorBrewer)   \n",
    "library(class)          \n",
    "library(e1071)          \n",
    "library(stringr)\n",
    "library(themis)\n",
    "devtools::install_github(\"tidymodels/tune\")\n",
    "set.seed(1)\n",
    "options(repr.matrix.max.rows = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eedd1813-ed7d-4f58-890a-dff46784e132",
   "metadata": {},
   "source": [
    "<b>Summarize the data in at least one table </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c346e0-de04-4d35-adae-1c83cb5487e1",
   "metadata": {},
   "source": [
    "We begin by reading in our dataset and tidying it by adding column names and removing any rows with missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e47eef-d5d1-44d7-b6fc-38cfa71beb0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pulsar_data_raw <- read_csv(\"pulsar_data.csv\", col_names = c(\"mean_integrated_profile\", \"stand_dev_integrated_profile\", \"exc_kurtosis_integrated_profile\", \n",
    "                                                         \"skew_integrated_profile\", \"mean_dmsnr\", \"stand_dev_dmsnr\", \"exc_kurtosis_dmsnr\", \n",
    "                                                         \"skew_dmsnr\", \"class\"))\n",
    "pulsar_data_raw <- pulsar_data |> \n",
    "    drop_na() |>\n",
    "    mutate(class = as_factor(class))\n",
    "head(pulsar_data)\n",
    "#not sure how to add table numbers\n",
    "#this is table 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9547a93a-e751-4a19-9e70-4799f98f4cc8",
   "metadata": {},
   "source": [
    "<b> Dataset Exploration Graph 1 (correlation): </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e927b2c-4f9e-4557-b5fe-a54c99b27c12",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "options(repr.plot.width = 12, repr.plot.height = 12)\n",
    "cor_pulse <- cor(pulsar_data_raw)\n",
    "corrplot(cor_pulse, type=\"upper\", order=\"hclust\",col=brewer.pal(n=8, name=\"RdYlBu\")) \n",
    "#need to add a \"Figure 1\" with a title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74437c16-426f-4f9f-bdbd-5b53413a3907",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "options(repr.plot.width = 17, repr.plot.height = 17)\n",
    "pm_pairs <- select(pulsar_data, \"mean_integrated_profile\":\"skew_dmsnr\")%>%\n",
    "ggpairs()\n",
    "\n",
    "pm_pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dce568e-0bcd-424b-ab84-be68cb75cfa9",
   "metadata": {},
   "source": [
    "We can see that various pairs of variables have a different correlation value, where some have higher correlation values than others. *** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103233dd-a390-46d3-97ac-d257507a0ba9",
   "metadata": {},
   "source": [
    "<b> Dataset Exploration Graph 2 (variable distribution): </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9c4c2c-2aa0-4db6-9e03-8af8bf263e2c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pulsar_data$class <- ifelse(pulsar_data$class == 1, \"P\", \"NP\")\n",
    "\n",
    "options(repr.plot.height = 13, repr.plot.width = 13)\n",
    "\n",
    "pulsar_data |> gather(predictors, value, -class) %>%\n",
    "  ggplot(aes(class, value, fill = class)) +\n",
    "  geom_boxplot() +\n",
    "  facet_wrap(~predictors, scales = \"free\", ncol = 4) +\n",
    "  theme(axis.text.x = element_blank(), legend.position=\"bottom\") +\n",
    "  theme(text = element_text(size = 18)) +\n",
    "  ggtitle(\"Figure 2: Variable Distribution\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c3b09b-cfbb-43cd-a131-773618bfce16",
   "metadata": {},
   "source": [
    "As shown above, the distribution graph above shows that some of the variables' values show a distinct difference between real and false pulsars."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2840a0df-c262-438e-b389-142d416e6430",
   "metadata": {},
   "source": [
    "Now, we look at the proportion of pulsars and non pulsars in the dataset to determine a data balancing method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c85961-7875-4665-a93b-614633a4c4df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prop.table(table(pulsar_data$class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d899b4-fc12-40c1-985a-11fa92a00a94",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "table(pulsar_data$class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89f4f11-69c4-4872-b359-ab3f931796b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rare_pulsar <- bind_rows(\n",
    "      filter(pulsar_data, class == \"P\"),\n",
    "      pulsar_data |> filter(class == \"NP\") |> slice_head(n = 3)\n",
    "    ) |>\n",
    "    select(class, skew_integrated_profile, skew_dmsnr)\n",
    "\n",
    "rare_plot <- rare_pulsar |>\n",
    "  ggplot(aes(x = skew_integrated_profile, y = skew_dmsnr, color = class)) +\n",
    "  geom_point(alpha = 0.5) +\n",
    "  labs(x = \"Skew Integrated Profile (standardized)\", \n",
    "       y = \"Skew dmsnr (standardized)\",\n",
    "       color = \"Class\") +\n",
    "  scale_color_manual(labels = c(\"Pulsar\", \"Non Pulsar\"), \n",
    "                     values = c(\"orange2\", \"steelblue2\")) +\n",
    "  theme(text = element_text(size = 18)) +\n",
    "  ggtitle(\"Figure 3: Class Proportions\")\n",
    "\n",
    "rare_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b945a217-ed00-4e47-b67b-d3f30bb12a10",
   "metadata": {},
   "source": [
    "As we can see from the proportions and the plot shown above in Figure 3, which uses two variables from the dataset, there are more non pulsars than pulsars. We must balance the number of pulsar points in the training set, otherwise our KNN classification model will be more likely to pick non pulsar as the majority class. Thus, the algorithm model will not learn correctly. \n",
    "\n",
    "For our purposes in this project, it will suffice to rebalance the data by oversampling the rare class. We will randomly duplicate observations of class 1 (real pulsars) until we have the same number of class 0 and class 1 in our training set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f77d6b78-dd84-4691-89a4-f2e1808562b0",
   "metadata": {
    "tags": []
   },
   "source": [
    "**Data Analysis**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7457429e-2084-4023-b09e-6dc06fe11b8a",
   "metadata": {},
   "source": [
    "To begin our data analysis, we must randomly split the dataset into a training and testing set and specify that 75% of the data to be used to train our classification model. The training set will be used to train and tune our model while the testing set will be used to test the accuracy of our classification model. We also set the seed so the random splitting of our dataset can be reproduced later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c456c7dc-35f4-477d-b566-81d293ec9411",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "set.seed(1)\n",
    "pulsar_split <- initial_split(pulsar_data, prop = 0.75, strata = class)\n",
    "pulsar_train <- training(pulsar_split)\n",
    "pulsar_test <- testing(pulsar_split) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f72f4a-44f6-46ef-bc84-50f420d530be",
   "metadata": {},
   "source": [
    "**Selecting Predictors**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3932bbb1-56bf-403b-b5c0-9c19a03a406e",
   "metadata": {},
   "source": [
    "To address our project question, we perform forward selection on the training set to determine how accurate our classification model would be, given various predictor combinations. For our purposes, it will be sufficient to use the training set to select our predictors as the training dataset is large enough. We will then select the set of predictors that is expected to yield the most accurate classifier in our data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35af64df-3782-4115-84d0-9ed572eb4e47",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "names <- colnames(pulsar_train |> select(-class))\n",
    "names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a816e5-0c5e-4ff7-8c70-fdd88db355d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "example_formula <- paste(\"class\", \"~\", paste(names, collapse=\"+\"))\n",
    "example_formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0871b1-5faa-4e50-9477-191a6ecb4e46",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create an empty tibble to store the results\n",
    "predictor_accuracies <- tibble(size = integer(), \n",
    "                     model_string = character(), \n",
    "                     accuracy = numeric())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c90c12-50e1-439f-91a8-720183fc0712",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# store the total number of predictors\n",
    "n_total <- length(names)\n",
    "\n",
    "# stores selected predictors\n",
    "selected <- c()\n",
    "\n",
    "# for every size from 1 to the total number of predictors\n",
    "for (i in 1:n_total) {\n",
    "    # for every predictor still not added yet\n",
    "    accs <- list()\n",
    "    models <- list()\n",
    "    for (j in 1:length(names)) {\n",
    "        # create a model string for this combination of predictors\n",
    "        preds_new <- c(selected, names[[j]])\n",
    "        model_string <- paste(\"class\", \"~\", paste(preds_new, collapse=\"+\"))\n",
    "\n",
    "        # create a recipe from the model string\n",
    "        puls_recipe <- recipe(as.formula(model_string), \n",
    "                                data = pulsar_train) |>\n",
    "                          step_scale(all_predictors()) |>\n",
    "                          step_center(all_predictors())                        \n",
    "        \n",
    "        #set up a model\n",
    "        knn_spec <- nearest_neighbor(weight_func = \"rectangular\", neighbors = tune()) |>\n",
    "            set_engine(\"kknn\") |>\n",
    "            set_mode(\"classification\")                                        \n",
    "\n",
    "        puls_vfold <- vfold_cv(pulsar_train, v = 10, strata = class)\n",
    "        \n",
    "        # tune the KNN classifier with these predictors\n",
    "        acc <- workflow() |>\n",
    "          add_recipe(puls_recipe) |>\n",
    "          add_model(knn_spec) |>\n",
    "          tune_grid(resamples = puls_vfold, grid = 10) |>\n",
    "          collect_metrics() |>\n",
    "          filter(.metric == \"accuracy\") |>\n",
    "          summarize(mx = max(mean))\n",
    "        acc <- acc$mx |> unlist()\n",
    "\n",
    "        # add this result to the dataframe\n",
    "        accs[[j]] <- acc\n",
    "        models[[j]] <- model_string\n",
    "    }\n",
    "    jstar <- which.max(unlist(accs))\n",
    "predictor_accuracies <- predictor_accuracies |> \n",
    "      add_row(size = i, \n",
    "              model_string = models[[jstar]], \n",
    "              accuracy = accs[[jstar]])\n",
    "    selected <- c(selected, names[[jstar]])\n",
    "    names <- names[-jstar]\n",
    "}\n",
    "predictor_accuracies\n",
    "#add table number"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8745b795-c699-4e97-b0c1-73fd9e460d5c",
   "metadata": {},
   "source": [
    "Based on the data above, the highest accuracy is obtained by using the 4 following predictors: exc_kurtosis_integrated_profile, stand_dev_dmsnr, stand_dev_integrated_profile, and mean_dmsnr."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5084f591-cec4-4cb0-9818-7983d6ec3406",
   "metadata": {},
   "source": [
    "Earlier, we saw that the percentage of observations corresponding to real pulsars is roughly 9%. A class imbalance is evident as there are more false pulsars than real pulsar observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f804ecb4-70e1-4a55-895f-aa14eaa2abbe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Class proportions in pulsar data set (Imbalanced)\n",
    "num_obs <- nrow(pulsar_data)\n",
    "pulsar_proportions <- pulsar_data |>\n",
    "    group_by(class) |>\n",
    "    summarize(n = n()) |>\n",
    "    mutate(percent = 100*n/nrow(pulsar_data))\n",
    "pulsar_proportions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3a496f-86a9-4d74-a88a-4ee4a4512e94",
   "metadata": {},
   "source": [
    "Here, we reproduce the random split of our data into a training and testing set with the \"set.seed\" function. We balance the proportions of real pulsars to false pulsar observations by upsampling the training set only, such that there is a ratio of 1:1 of real pulsars and false pulsars. The testing set will not be upsampled as this will be used to test our accuracy. To preprocess the data, we scale and center our predictors such that the variables have a mean of 0 and standard deviation of 1. We also build our recipe with the 4 predictors that yields the highest performance, obtained from forward selection. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18e7624-7e36-4f57-b9c5-0d0823d722f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "set.seed(1)\n",
    "pulsar_split <- initial_split(pulsar_data, prop = 0.75, strata = class)\n",
    "pulsar_train <- training(pulsar_split)\n",
    "pulsar_test <- testing(pulsar_split) \n",
    "\n",
    "\n",
    "#Standardize and Upsample data to balance the training set\n",
    "pulsar_recipe <- recipe(class ~ exc_kurtosis_integrated_profile, \n",
    "                        stand_dev_dmsnr, \n",
    "                        stand_dev_integrated_profile, \n",
    "                        mean_dmsnr, data = pulsar_train) |>                   #input the 4 predictors we obtained from forward selection\n",
    "    step_scale(all_predictors()) |>\n",
    "    step_center(all_predictors()) |>\n",
    "    themis::step_upsample(class, over_ratio = 1, skip = FALSE) |>\n",
    "    prep()\n",
    "pulsar_recipe\n",
    "\n",
    "pulsar_train <- bake(pulsar_recipe, pulsar_train)\n",
    "pulsar_train\n",
    "\n",
    "pulsar_recipe <- recipe(class ~ ., data = pulsar_train)\n",
    "\n",
    "#Check new proportions in training set\n",
    "new_pulsar_proportions <- pulsar_train |>\n",
    "    group_by(class) |>\n",
    "    summarize(n = n()) |>\n",
    "    mutate(percent = 100*n/nrow(pulsar_train))\n",
    "new_pulsar_proportions\n",
    "#add table number"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238bd6de-c1ef-45c5-bdf3-0c857686f94a",
   "metadata": {},
   "source": [
    "Now we perform cross-validation on the training set in order to select the best K parameter value for our classifier (number of neighbors). To do this, we perform 10-fold cross-validation. But first, we build a classification model that specifies that the number of neighbors to tune. We also create a tibble that contains each K value that we want to test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ebb63d-702f-43a2-a0ee-dc200ab384a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#build the model\n",
    "knn_spec <- nearest_neighbor(weight_func = \"rectangular\", neighbors = tune()) |>\n",
    "            set_engine(\"kknn\") |>\n",
    "            set_mode(\"classification\")\n",
    "\n",
    "#Create a tibble for the K values\n",
    "k_vals <- tibble(neighbors = seq(from = 1, to = 100, by = 3))\n",
    "#k_vals       #add table number\n",
    "\n",
    "#Set up and perform 10 fold cross validation\n",
    "pulsar_vfold <- vfold_cv(pulsar_train, v = 10, strata = class)\n",
    "\n",
    "knn_results <- workflow() |>\n",
    "               add_recipe(pulsar_recipe) |>\n",
    "               add_model(knn_spec) |>\n",
    "               tune_grid(resamples = pulsar_vfold, grid = k_vals) |>\n",
    "               collect_metrics() #assess the accuracy \n",
    "knn_results\n",
    "#add table number"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dce61f3-3eec-49bd-a53e-ba534e3cf442",
   "metadata": {},
   "source": [
    "To determine the best K to use, we filter the metrics collected from cross validation and plot the accuracy against the K values we tested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3dad9b6-9233-474f-b1cb-eedb8b441f6a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "accuracies <- knn_results |> \n",
    "       filter(.metric == \"accuracy\")\n",
    "\n",
    "accuracy_versus_k <- ggplot(accuracies, aes(x = neighbors, y = mean))+\n",
    "       geom_point() +\n",
    "       geom_line() +\n",
    "       labs(x = \"Neighbors\", y = \"Accuracy Estimate\") +\n",
    "       ggtitle(\" Figure 4: Accuracy vs. K\") +\n",
    "       theme(text = element_text(size = 20))\n",
    "accuracy_versus_k"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c175223-e80b-4e90-afd3-b872e2bbff7a",
   "metadata": {},
   "source": [
    "Based on the above plot, we see that the accuracy decreases quite steeply as the number of neighbors increases, before leveling off from around K = 16 onwards. We choose K = 17 for our classification model because the accuracy is high at this point, and the accuracy does not change drastically when looking at similar K values. Overall, we want to avoid overfitting the data by selecting too few neighbors, and 17 is an odd number (given that K-nearest neighbors classifies observations based on a majority rules system, using an even number of neighbors could be problematic in the event of a tie, since our class variable is binary). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94cc5c8-f7b7-462b-9dc3-ad4d81cdd5de",
   "metadata": {},
   "source": [
    "Upon determining the optimal K value for our classifier, we can finally predict on our testing set. As done below, we use the same recipe as before, but a new model that specifies the number of neighbors, k = 17 is built. Once we have used the model to predict the classes of the observations in the test set, we take a confusion matrix to view the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8248be-dd71-44eb-bc6a-cc64a680de11",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "knn_spec_final <- nearest_neighbor(weight_func = \"rectangular\", neighbors = 17) |>\n",
    "                    set_engine(\"kknn\") |>\n",
    "                    set_mode(\"classification\")\n",
    "\n",
    "pulsar_fit_final <- workflow() |>\n",
    "        add_recipe(pulsar_recipe) |>\n",
    "        add_model(knn_spec_final) |>\n",
    "        fit(data = pulsar_train)\n",
    "\n",
    "pulsar_test_predictions_final <-  predict(pulsar_fit_final, pulsar_test) |>\n",
    "        bind_cols(pulsar_test)\n",
    "\n",
    "pulsar_test_predictions_final                \n",
    "\n",
    "confusion_final <- pulsar_test_predictions_final |>\n",
    "    conf_mat(truth = class, estimate = .pred_class)\n",
    "confusion_final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80337786-6d08-450c-8231-061bc18bf298",
   "metadata": {},
   "source": [
    "To visualize the accuracy of our classification model, we create a new column in the predictions table that will allow us to produce a visualization of the test data in such a way that colour-coding the observations will provide further insight on information stored in the confusion matrix. (***not worded very well)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ab16dc-0121-4492-b614-091faa0061ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mutated_predictions <- pulsar_test_predictions_final |>\n",
    "    mutate(new_cat = case_when(.pred_class == 0 & class == 0 ~ \"False pulsar, correctly classified\",\n",
    "                               .pred_class == 1 & class == 1 ~ \"Real pulsar, correctly classified\",\n",
    "                               .pred_class == 1 & class == 0 ~ \"False pulsar, incorrectly classified\",\n",
    "                               .pred_class == 0 & class == 1 ~ \"Real pulsar, incorrectly classified\"))\n",
    "mutated_predictions\n",
    "#add table number"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd50700-bf7e-4cf7-a342-d02cb65b0153",
   "metadata": {},
   "source": [
    "<b> Visualization: Classifier accuracy </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab9c464-84ad-4a16-b9c8-855c6d16031f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "options(repr.plot.height = 10, repr.plot.width = 14)\n",
    "\n",
    "#First 2 predictors\n",
    "plot_1 <- ggplot() +\n",
    "    geom_point(data = mutated_predictions, mapping = aes(x = exc_kurtosis_integrated_profile, \n",
    "                                                              y = mean_dmsnr, colour = new_cat), alpha = 0.5) +\n",
    "    labs(x = \"Scaled Excess Kurtosis - Integrated Profile\", y = \"Scaled Mean - DMSNR curve\", colour = \"Prediction\") +\n",
    "    ggtitle(\"Figure 5: Classifier accuracy with regards to mean of DMSNR\n",
    "                \\ncurve and excess kurtosis of integrated profile\") +\n",
    "    scale_color_brewer(palette = \"Dark2\") +\n",
    "    theme(text = element_text(size = 20))\n",
    "plot_1\n",
    "\n",
    "\n",
    "\n",
    "#Next 2 predictors\n",
    "plot_2 <- ggplot() +\n",
    "    geom_point(data = mutated_predictions, mapping = aes(x = skew_dmsnr,\n",
    "                                                              y = skew_integrated_profile, colour = new_cat), alpha = 0.5) +\n",
    "    labs(x = \"Scaled Skewness - DMSNR curve\", y = \"Scaled Skewness - Integrated Profile\", colour = \"Prediction\") +\n",
    "    ggtitle(\"Figure 6: Classifier accuracy with regards to skewkness\n",
    "                \\nof both DMSNR curve and integrated profile\") +\n",
    "    scale_color_brewer(palette = \"Dark2\") +\n",
    "    theme(text = element_text(size = 20))\n",
    "plot_2\n",
    "\n",
    "\n",
    "\n",
    "#Last 2 predictors\n",
    "plot_3 <- ggplot() +\n",
    "    geom_point(data = mutated_predictions, mapping = aes(x = stand_dev_integrated_profile, \n",
    "                                                             y = exc_kurtosis_dmsnr, colour = new_cat), alpha = 0.5) +\n",
    "    labs(x = \"Scaled Standard Deviation - Integrated Profile\", y = \"Scaled Excess Kurtosis - DMSNR curve\", colour = \"Prediction\") +\n",
    "    ggtitle(\"Figure 7: Classifier accuracy with regards to excess kurtosis of\n",
    "                \\nDMSNR curve and standard deviation of integrated profile\") +\n",
    "    scale_color_brewer(palette = \"Dark2\") +\n",
    "    theme(text = element_text(size = 20))\n",
    "plot_3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511f40e0-0a1a-4b35-862c-f6e1cab7a207",
   "metadata": {},
   "source": [
    "As can be seen above, there are very few observations in the testing set that were incorrectly classified. This indicates that our model is quite accurate. We can represent the accuracy of our model as a percentage, as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2d99de-ed02-480e-8fc3-0e92d18fed0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#From the confusion matrix:\n",
    "\n",
    "accuracy_perc <- ((3838 + 3853)/8130)*100\n",
    "accuracy_perc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0cce850-d0c1-4a2b-a29a-0d4c27d51260",
   "metadata": {},
   "source": [
    "Therefore, <b> ~__% </b> is a good estimate of how accuracte our classification model is."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e75e84a-fc2f-4ad1-9499-4b7f7bed1fed",
   "metadata": {},
   "source": [
    "<b>Discussion </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b8cada9-9701-4662-b305-866fa4825139",
   "metadata": {},
   "source": [
    "summarize what you found: \n",
    "\n",
    "We found that training a classifier with our predictors (name them*) yields the most accurate predictions on new observations (i.e. the testing set). The accuracy of our model is __.\n",
    "\n",
    "The high accuracy of the model trained with the predictors from the HTRU2 data set on new observations, as reflected in the testing set, is an interesting and promising finding. It suggests that the predictors used in the model are indeed effective in identifying pulsar candidates, which aligns with the initial hypothesis of the study. \n",
    "\n",
    "(Before upsampling I wasn’t expecting a really high prediction accuracy with any combination of predictors, due to how rare the real pulsars were in the original dataset\n",
    "-Also, I don’t think I was expecting that the most accurate classifier would come from using 6 of the 8 variables available to us in the dataset → in our class readings it was mentioned that using very few or many predictors often harms how good the classifier is at making predictions (would have expected between 2-4 predictors to give the highest accuracy)→ **Due to the rarity of real pulsars in the original dataset, we did not expect to achieve a high prediction accuracy with any combination of predictors prior to upsampling. In addition, in contrast to what we had anticipated, we discovered that using 6 of the dataset's 8 available variables allowed us to create the most accurate classifier. This was unexpected because we had read in class that using either too few or too many predictors could reduce the classifier's accuracy, and we had anticipated that using 2-4 predictors would produce the highest accuracy. This unexpected result casts doubt on accepted wisdom and emphasises the nuanced interplay between predictor choice and pulsar classification prediction accuracy. It is necessary to conduct additional research and analysis to comprehend the underlying**\n",
    "\n",
    "\n",
    "The accurate prediction of new observations can help validate the existence of pulsars and provide insights into their properties, which could improve our understanding of pulsar candidates and their characteristics. This may increase our understanding of astrophysical processes and enhance our capacity to find and investigate pulsars in the future. Furthermore, the model's accuracy may have useful implications for pulsar research. It might be used, for instance, to streamline the procedure for picking pulsar candidates in extensive surveys like the High Time Resolution Universe Survey.\n",
    "\n",
    "The accuracy of the model might be improved through further research and comparisons with current approaches, which would also advance pulsar classification techniques.Additionally, the model's accuracy could be compared to other existing methods or models to assess its superiority and potential for further improvement.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c5f4b5-a704-4ce1-bf06-579b54b9f3b8",
   "metadata": {},
   "source": [
    "**References**\n",
    "\n",
    "Dr Robert Lyon, University of Manchester, School of Physics and Astronomy, Alan Turing Building, Manchester M13 9PL, United Kingdom, robert.lyon '@' manchester.ac.uk\n",
    "\n",
    "Keith, M. J., et al. (2010). The HTRU survey. Handbook of pulsar astronomy, 379-422.\n",
    "\n",
    "United States. National Aeronautics and Space Administration. NASA technical note. Washington :National Aeronautics and Space Administration.\n",
    "\n",
    "Paula, G. (2020, February 5). Creating a new variable under conditions of other two variables. Posit Community. Retrieved April 13, 2023, from https://community.rstudio.com/t/creating-a-new-variable-under-conditions-of-other-two-variables/51825  \n",
    "\n",
    "do we need to cite the textbook?\n",
    "do we need embedded citations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10af3ded-fe1b-4137-8f5b-d18d0a90f2ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.2.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
