{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e3fcf7c-e9ec-4fd2-98a5-04d5534251fa",
   "metadata": {},
   "source": [
    "<b> Title: </b> Group 11 Final Project Report - DSCI 100 002 \n",
    "\n",
    "<b> Group members: </b> Katie Archer, Noor Naila Imtinan Himam, Matthew Yeung, Wenwen Zhao"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b692e83d-b171-416f-bad7-d00f894b36c9",
   "metadata": {},
   "source": [
    "<b>1. Introduction</b>\n",
    "<br>\n",
    "According to scientific research, pulsars are an uncommon form of neutron stars that emit regular pulses of radiation, varying from several seconds to milliseconds in frequency. The potent magnetic fields of these stars generate intense beams of light at both poles. These beams are periodically observed as the pulsar rotates quickly, and they can only be observed with large telescopes when they cross our line of sight from Earth (National Aeronautics and Space Administration, n.d.)\n",
    "\n",
    "Although pulsars emit a pattern of radio emission that can be detected as they rotate, it can be challenging to distinguish between genuine signals and background noise. Pulsar candidates are being classified as binary classification issues using machine learning tools. The HTRU 2 dataset, which is used to train classification models, includes examples of both real and fake pulsar signals. The class labels used are 0 (negative) and 1 (positive), with the legitimate pulsar examples being the minority positive class. The eight continuous variables are obtained from the integrated pulse profile and the DM-SNR (Disperion Measure - Signal-to-Noise Ratio) curve, which describe the longitude-resolved version of the signal averaged in both time and frequency (Keith et al., 2010). Each candidate in the dataset is described by eight continuous variables, one class variable, and no astronomical information. The integrated pulse profile and the DM-SNR curve are used to determine the eight variables.\n",
    "\n",
    "In this project, we aim to figure out if information from the integrated pulse profile and DM-SNR curve of pulsar candidates can be used to classify whether signals are legitimate or spurious (real or fake pulsar) with high accuracy, and if so, which predictors will lead to the greatest accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c4c763-a084-475b-b915-8832b6234d1b",
   "metadata": {},
   "source": [
    "<b>2. Preliminary exploratory data analysis:</b>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4b953b-9773-4582-8247-c17372463d1c",
   "metadata": {},
   "source": [
    "First, we load all of the libraries that we will need for the remainder of this project. This includes installing a package that will allow us to upsample our dataset later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57f97abf-d9bd-4147-95b2-c1a0c8da1e41",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "also installing the dependencies ‘RANN’, ‘ROSE’\n",
      "\n",
      "\n",
      "Updating HTML index of packages in '.Library'\n",
      "\n",
      "Making 'packages.html' ...\n",
      " done\n",
      "\n",
      "Updating HTML index of packages in '.Library'\n",
      "\n",
      "Making 'packages.html' ...\n",
      " done\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#CAUTION: Takes a long time to load.\n",
    "install.packages(\"themis\")\n",
    "install.packages(\"tidymodels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe00850e-2b65-4da2-96e2-08ae49344ad4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating HTML index of packages in '.Library'\n",
      "\n",
      "Making 'packages.html' ...\n",
      " done\n",
      "\n",
      "Skipping install of 'tune' from a github remote, the SHA1 (597ddf7a) has not changed since last install.\n",
      "  Use `force = TRUE` to force installation\n",
      "\n"
     ]
    }
   ],
   "source": [
    "library(tidyverse)\n",
    "library(repr)\n",
    "library(tidymodels)\n",
    "library(dplyr)\n",
    "library(ggplot2)\n",
    "library(GGally)\n",
    "install.packages(\"corrplot\")\n",
    "library(corrplot)\n",
    "library(RColorBrewer)   \n",
    "library(class)          \n",
    "library(e1071)          \n",
    "library(stringr)\n",
    "library(themis)\n",
    "devtools::install_github(\"tidymodels/tune\")\n",
    "set.seed(1)\n",
    "options(repr.matrix.max.rows = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eedd1813-ed7d-4f58-890a-dff46784e132",
   "metadata": {},
   "source": [
    "<b>Summarize the data in at least one table </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c346e0-de04-4d35-adae-1c83cb5487e1",
   "metadata": {},
   "source": [
    "We begin by reading in our dataset and tidying it by adding column names and removing any rows with missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "27e47eef-d5d1-44d7-b6fc-38cfa71beb0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in base::nchar(wide_chars$test, type = \"width\"):\n",
      "“restarting interrupted promise evaluation”\n",
      "Warning message in base::nchar(wide_chars$test, type = \"width\"):\n",
      "“internal error -3 in R_decompress1”\n"
     ]
    },
    {
     "ename": "ERROR",
     "evalue": "Error in base::nchar(wide_chars$test, type = \"width\"): lazy-load database '/opt/conda/lib/R/library/cli/R/sysdata.rdb' is corrupt\n",
     "output_type": "error",
     "traceback": [
      "Error in base::nchar(wide_chars$test, type = \"width\"): lazy-load database '/opt/conda/lib/R/library/cli/R/sysdata.rdb' is corrupt\nTraceback:\n",
      "1. read_csv(\"pulsar_data.csv\", col_names = c(\"mean_integrated_profile\", \n .     \"stand_dev_integrated_profile\", \"exc_kurtosis_integrated_profile\", \n .     \"skew_integrated_profile\", \"mean_dmsnr\", \"stand_dev_dmsnr\", \n .     \"exc_kurtosis_dmsnr\", \"skew_dmsnr\", \"class\"))",
      "2. vroom::vroom(file, delim = \",\", col_names = col_names, col_types = col_types, \n .     col_select = {\n .         {\n .             col_select\n .         }\n .     }, id = id, .name_repair = name_repair, skip = skip, n_max = n_max, \n .     na = na, quote = quote, comment = comment, skip_empty_rows = skip_empty_rows, \n .     trim_ws = trim_ws, escape_double = TRUE, escape_backslash = FALSE, \n .     locale = locale, guess_max = guess_max, show_col_types = show_col_types, \n .     progress = progress, altrep = lazy, num_threads = num_threads)",
      "3. show_col_types(out, locale)",
      "4. show_dims(x)",
      "5. cli_block(class = \"vroom_dim_message\", {\n .     cli::cli_text(\"\\n      {.strong Rows: }{.val {NROW(x)}}\\n      {.strong Columns: }{.val {NCOL(x)}}\\n      \")\n . })",
      "6. withCallingHandlers(expr, message = function(x) {\n .     msg <<- paste0(msg, x$message)\n .     invokeRestart(\"muffleMessage\")\n . })",
      "7. cli::cli_text(\"\\n      {.strong Rows: }{.val {NROW(x)}}\\n      {.strong Columns: }{.val {NCOL(x)}}\\n      \")",
      "8. cli__message(\"text\", list(text = glue_cmd(..., .envir = .envir)))",
      "9. cli__message_emit(cond)",
      "10. withRestarts({\n  .     signalCondition(cond)\n  .     cli__default_handler(cond)\n  . }, cli_message_handled = function() NULL)",
      "11. withOneRestart(expr, restarts[[1L]])",
      "12. doWithOneRestart(return(expr), restart)",
      "13. cli__default_handler(cond)",
      "14. cli_server_default(msg)",
      "15. cli_server_default_safe(msg)",
      "16. do.call(app[[type]], msg$args)",
      "17. (function (text) \n  . clii_text(app, text))(text = structure(list(str = structure(\"{FCkNXbE-5.strong Rows: FCkNXbE-5}{FCkNXbE-5.val {FCkNXbE-5v5FCkNXbE-5}FCkNXbE-5}\\n{FCkNXbE-5.strong Columns: FCkNXbE-5}{FCkNXbE-5.val {FCkNXbE-5v6FCkNXbE-5}FCkNXbE-5}\", class = c(\"glue\", \n  . \"character\")), values = <environment>), class = \"cli_glue_delay\"))",
      "18. clii_text(app, text)",
      "19. app$xtext(text)",
      "20. clii__xtext(app, text, .list = .list, indent = indent, padding = padding)",
      "21. ansi_strwrap(text, exdent = exdent, width = app$get_width(extra = padding))",
      "22. unicode_pre(x)",
      "23. setup_unicode_width_fix()",
      "24. base::nchar(wide_chars$test, type = \"width\")"
     ]
    }
   ],
   "source": [
    "pulsar_data <- read_csv(\"pulsar_data.csv\", col_names = c(\"mean_integrated_profile\", \"stand_dev_integrated_profile\", \"exc_kurtosis_integrated_profile\", \n",
    "                                                         \"skew_integrated_profile\", \"mean_dmsnr\", \"stand_dev_dmsnr\", \"exc_kurtosis_dmsnr\", \n",
    "                                                         \"skew_dmsnr\", \"class\"))\n",
    "pulsar_data <- pulsar_data |> drop_na()\n",
    "head(pulsar_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9547a93a-e751-4a19-9e70-4799f98f4cc8",
   "metadata": {},
   "source": [
    "<b> Dataset Exploration Graph 1 (correlation): </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e927b2c-4f9e-4557-b5fe-a54c99b27c12",
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in is.data.frame(x): object 'pulsar_data' not found\n",
     "output_type": "error",
     "traceback": [
      "Error in is.data.frame(x): object 'pulsar_data' not found\nTraceback:\n",
      "1. cor(pulsar_data)",
      "2. is.data.frame(x)"
     ]
    }
   ],
   "source": [
    "cor_pulse <- cor(pulsar_data)\n",
    "corrplot(cor_pulse, type=\"upper\", order=\"hclust\",col=brewer.pal(n=8, name=\"RdYlBu\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dce568e-0bcd-424b-ab84-be68cb75cfa9",
   "metadata": {},
   "source": [
    "We can see that there is a different correlation value between the variables where some of them are high value.*** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103233dd-a390-46d3-97ac-d257507a0ba9",
   "metadata": {},
   "source": [
    "<b> Dataset Exploration Graph 2 (variable distribution): </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9c4c2c-2aa0-4db6-9e03-8af8bf263e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pulsar_data$class <- ifelse(pulsar_data$class == 1, \"P\", \"NP\")\n",
    "\n",
    "options(repr.plot.height = 12, repr.plot.width = 13)\n",
    "\n",
    "pulsar_data |> gather(predictors, value, -class) %>%\n",
    "  ggplot(aes(class, value, fill = class)) +\n",
    "  geom_boxplot() +\n",
    "  facet_wrap(~predictors, scales = \"free\", ncol = 4) +\n",
    "  theme(axis.text.x = element_blank(), legend.position=\"bottom\") +\n",
    "  theme(text = element_text(size = 18))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c3b09b-cfbb-43cd-a131-773618bfce16",
   "metadata": {},
   "source": [
    "As shown above, the distribution graph above shows that some of the variables' values show an evident difference between real and fake pulsars."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2840a0df-c262-438e-b389-142d416e6430",
   "metadata": {},
   "source": [
    "Now, we will see the proportion of pulsar and non pulsar dataset to determine a data balancing method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c85961-7875-4665-a93b-614633a4c4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "prop.table(table(pulsar_data$class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d899b4-fc12-40c1-985a-11fa92a00a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "table(pulsar_data$class)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3dd4834-0b8b-413f-86eb-b1f38350b065",
   "metadata": {},
   "source": [
    "rare_pulsar <- bind_rows(\n",
    "      filter(pulsar_data, class == \"P\"),\n",
    "      pulsar_data |> filter(class == \"NP\") |> slice_head(n = 3)\n",
    "    ) |>\n",
    "    select(class, skew_integrated_profile, skew_dmsnr)\n",
    "\n",
    "rare_plot <- rare_pulsar |>\n",
    "  ggplot(aes(x = skew_integrated_profile, y = skew_dmsnr, color = class)) +\n",
    "  geom_point(alpha = 0.5) +\n",
    "  labs(x = \"Skew Integrated Profile (standardized)\", \n",
    "       y = \"Skew dmsnr (standardized)\",\n",
    "       color = \"Diagnosis\") +\n",
    "  scale_color_manual(labels = c(\"Pulsar\", \"Non Pulsar\"), \n",
    "                     values = c(\"orange2\", \"steelblue2\")) +\n",
    "  theme(text = element_text(size = 12))\n",
    "\n",
    "rare_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b945a217-ed00-4e47-b67b-d3f30bb12a10",
   "metadata": {},
   "source": [
    "As we can see from the proportion and plot, we have to balance the train data set. Otherwise we will not learn correctly. Indeed, the algorithm will not have enough information about Pulsar Star.\n",
    "\n",
    "For the present purposes, it will suffice to rebalance the data by oversampling the rare class. In other words, we will duplicate randomly observations of class 1 until we have the same number of class 0 and class 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f72f4a-44f6-46ef-bc84-50f420d530be",
   "metadata": {},
   "source": [
    "**Selecting Predictors**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3932bbb1-56bf-403b-b5c0-9c19a03a406e",
   "metadata": {},
   "source": [
    "To address our project question, we perform steps to determine an estimate of how accuracte our classififcation model would be, given various predictor combinations. We will select the set of predictors that is expected to yield the most accuract classifier to use in our data analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ff1da0-c642-4823-b706-7a55b09458a6",
   "metadata": {
    "tags": []
   },
   "source": [
    "Here, we split our dataset into training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa3ce5e-e1bb-40e5-83f1-5bcbfbaa4cc5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "set.seed(1)\n",
    "pulsar_split <- initial_split(standardized_pulsar, prop = 0.75, strata = class)\n",
    "pulsar_train <- training(pulsar_split)\n",
    "pulsar_test <- testing(pulsar_split) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35af64df-3782-4115-84d0-9ed572eb4e47",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "names <- colnames(pulsar_train |> select(-class))\n",
    "names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a816e5-0c5e-4ff7-8c70-fdd88db355d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_formula <- paste(\"class\", \"~\", paste(names, collapse=\"+\"))\n",
    "example_formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0871b1-5faa-4e50-9477-191a6ecb4e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an empty tibble to store the results\n",
    "predictor_accuracies <- tibble(size = integer(), \n",
    "                     model_string = character(), \n",
    "                     accuracy = numeric())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c90c12-50e1-439f-91a8-720183fc0712",
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the total number of predictors\n",
    "n_total <- length(names)\n",
    "\n",
    "# stores selected predictors\n",
    "selected <- c()\n",
    "\n",
    "# for every size from 1 to the total number of predictors\n",
    "for (i in 1:n_total) {\n",
    "    # for every predictor still not added yet\n",
    "    accs <- list()\n",
    "    models <- list()\n",
    "    for (j in 1:length(names)) {\n",
    "        # create a model string for this combination of predictors\n",
    "        preds_new <- c(selected, names[[j]])\n",
    "        model_string <- paste(\"class\", \"~\", paste(preds_new, collapse=\"+\"))\n",
    "\n",
    "        # create a recipe from the model string\n",
    "        pulsar_recipe <- recipe(as.formula(model_string), \n",
    "                                data = pulsar_train) |>\n",
    "                          step_scale(all_predictors()) |>\n",
    "                          step_center(all_predictors())\n",
    "\n",
    "        # tune the KNN classifier with these predictors, \n",
    "        # and collect the accuracy for the best K\n",
    "        acc <- workflow() |>\n",
    "          add_recipe(pulsar_recipe) |>\n",
    "          add_model(knn_spec) |>\n",
    "          tune_grid(resamples = pulsar_vfold, grid = 10) |>\n",
    "          collect_metrics() |>\n",
    "          filter(.metric == \"accuracy\") |>\n",
    "          summarize(mx = max(mean))\n",
    "        acc <- acc$mx |> unlist()\n",
    "\n",
    "        # add this result to the dataframe\n",
    "        accs[[j]] <- acc\n",
    "        models[[j]] <- model_string\n",
    "    }\n",
    "    jstar <- which.max(unlist(accs))\n",
    "predictor_accuracies <- predictor_accuracies |> \n",
    "      add_row(size = i, \n",
    "              model_string = models[[jstar]], \n",
    "              accuracy = accs[[jstar]])\n",
    "    selected <- c(selected, names[[jstar]])\n",
    "    names <- names[-jstar]\n",
    "}\n",
    "predictor_accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8745b795-c699-4e97-b0c1-73fd9e460d5c",
   "metadata": {},
   "source": [
    "Based on the data above, the highest accuracy is obtained by having exc_kurtosis_integrated_profile, skew_dmsnr, stand_dev_integrated_profile, and mean_dmsnr as predictors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4678b22f-2356-481d-8412-01d7aa16fabb",
   "metadata": {},
   "source": [
    "<b>Methods </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2260c77d-3973-4fc0-8d3c-02e41c76158c",
   "metadata": {},
   "source": [
    "General steps:\n",
    "1. Standardize values of skewness of the integrated profile and DM-SNR curve to use as predictors, will predict for class\n",
    "2. Split training set further, perform 5-fold cross validation to determine best K-value\n",
    "3. Build classification model, train entire training set with the best K-value\n",
    "4. Predict on the testing set, assess model's accuracy by collecting metrics and creating visualizations\n",
    "\n",
    "One way that we will visualize our results is through a scatter plot with the predictor variables on the x- and y- axes and each point representing an observation in the testing set. We will colour code the points by class, in terms of whether or not our model classified them correctly. We will use 4 colours; one to indicate that an observation was predicted correctly as a real pulsar, one to indicate that an observation was predicted correctly as a false pulsar, one to indicate that an observation was predicted incorrectly as a real pulsar when in the testing set it was labelled as fake, and a final one to indicate that an observation was predicted incorrectly as a false pulsar when in fact it was real as labelled in the testing set. This will give a visual of how accurate the model was, and for which values of the standardized predictors the model had the most trouble classifying candidates correctly.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e18e0b-7b31-4b16-a9f2-425f701f94e7",
   "metadata": {},
   "source": [
    "<b>Data Analysis and Results </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5084f591-cec4-4cb0-9818-7983d6ec3406",
   "metadata": {},
   "source": [
    "Since we loaded all of our libraries at the beginning of this report, and we have already read in our data, we can start by inspecting the dataset. We see that the percentage of observations corresponding to real pulsars is around 9%. Then, to preprocess the data, we scale and center our 4 predictors so that the variables have a mean of 0 and standard deviation of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f804ecb4-70e1-4a55-895f-aa14eaa2abbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add columns\n",
    "unscaled_data <- read_csv(\"pulsar_data.csv\", \n",
    "                        col_names = c(\"mean_integrated_profile\", \n",
    "                                      \"stand_dev_integrated_profile\", \n",
    "                                      \"exc_kurtosis_integrated_profile\", \n",
    "                                      \"skew_integrated_profile\",\n",
    "                                      \"mean_dmsnr\", \n",
    "                                      \"stand_dev_dmsnr\", \n",
    "                                      \"exc_kurtosis_dmsnr\", \n",
    "                                      \"skew_dmsnr\", \"class\")) \n",
    "\n",
    "unscaled_data <- unscaled_data |>\n",
    "    drop_na() |>\n",
    "    mutate(class = as_factor(class))\n",
    "#unscaled_data \n",
    "\n",
    "#Class proportions in pulsar training set (Imbalanced)\n",
    "num_obs <- nrow(pulsar_train)\n",
    "pulsar_proportions <- pulsar_train |>\n",
    "    group_by(class) |>\n",
    "    summarize(n = n()) |>\n",
    "    mutate(percent = 100*n/nrow(pulsar_train))\n",
    "pulsar_proportions\n",
    "\n",
    "#Scale data\n",
    "pulsar_recipe <- recipe(class ~ exc_kurtosis_integrated_profile + skew_dmsnr + stand_dev_integrated_profile + \n",
    "                        mean_dmsnr + skew_integrated_profile + exc_kurtosis_dmsnr, data = pulsar_train) |>\n",
    "    step_scale(all_predictors()) |>\n",
    "    step_center(all_predictors()) |>\n",
    "    prep()\n",
    "\n",
    "standardized_pulsar <- bake(pulsar_recipe, pulsar_train)\n",
    "standardized_pulsar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3a496f-86a9-4d74-a88a-4ee4a4512e94",
   "metadata": {},
   "source": [
    "Here, we split our preprocessed data into training and testing sets, and put 75% of the data into the training set. As mentioned earlier, to balance the proportion of real pulsar observations to false pulsar observations, we upsample the portion of the dataset that we want to use to train our model (i.e. create more real pulsar observations that have predictor values similar to those in the original set). We also build our recipe given our chosen predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c18e7624-7e36-4f57-b9c5-0d0823d722f5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in parse(text = x, srcfile = src): The pipe operator requires a function call as RHS\n",
     "output_type": "error",
     "traceback": [
      "Error in parse(text = x, srcfile = src): The pipe operator requires a function call as RHS\nTraceback:\n"
     ]
    }
   ],
   "source": [
    "set.seed(1)\n",
    "pulsar_split <- initial_split(standardized_pulsar, prop = 0.75, strata = class)\n",
    "pulsar_train <- training(pulsar_split)\n",
    "pulsar_test <- testing(pulsar_split) \n",
    "\n",
    "#Check class proportions in the training set\n",
    "pulsar_proportions <- pulsar_train |>\n",
    "    group_by(class) |>\n",
    "    summarize(n = n()) |>\n",
    "    mutate(percent = 100*n/nrow(pulsar_train))\n",
    "pulsar_proportions\n",
    "\n",
    "#Upscale data to balance training set\n",
    "pulsar_recipe <- recipe(class ~ exc_kurtosis_integrated_profile+skew_dmsnr+stand_dev_integrated_profile+mean_dmsnr,\n",
    "                        data = pulsar_train) |>\n",
    "    step_upsample(class, over_ratio = 1, skip = FALSE) |>\n",
    "    prep |>\n",
    "pulsar_recipe\n",
    "\n",
    "pulsar_train <- bake(pulsar_recipe, pulsar_train)\n",
    "pulsar_train\n",
    "\n",
    "#Check new proportions in training set\n",
    "new_pulsar_proportions <- pulsar_train |>\n",
    "    group_by(class) |>\n",
    "    summarize(n = n()) |>\n",
    "    mutate(percent = 100*n/nrow(pulsar_train))\n",
    "new_pulsar_proportions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238bd6de-c1ef-45c5-bdf3-0c857686f94a",
   "metadata": {},
   "source": [
    "Now we perform cross validation on the training set in order to select the best K value for our classifier (number of neighbors). To do this, we use 10 folds. But first, we build a classification model that specifies that we want to tune the number of neighbors. We create a tibble that contains each K value that we want to test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ebb63d-702f-43a2-a0ee-dc200ab384a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#build the model, CAUTION: Takes a long time to load.\n",
    "knn_spec <- nearest_neighbor(weight_func = \"rectangular\", neighbors = tune()) |>\n",
    "            set_engine(\"kknn\") |>\n",
    "            set_mode(\"classification\")\n",
    "\n",
    "#Create a tibble for the K values\n",
    "k_vals <- tibble(neighbors = seq(from = 1, to = 75, by = 3))\n",
    "#k_vals\n",
    "\n",
    "#Set up and perform 10 fold cross validation\n",
    "pulsar_vfold <- vfold_cv(pulsar_train, v = 10, strata = class)\n",
    "\n",
    "knn_results <- workflow() |>\n",
    "               add_recipe(pulsar_recipe) |>\n",
    "               add_model(knn_spec) |>\n",
    "               tune_grid(resamples = pulsar_vfold, grid = k_vals) |>\n",
    "               collect_metrics() #assess the accuracy \n",
    "knn_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dce61f3-3eec-49bd-a53e-ba534e3cf442",
   "metadata": {},
   "source": [
    "To determine the best K to use, we filter the collected metrics from cross validation and plot the accuracy against the K values we tested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3dad9b6-9233-474f-b1cb-eedb8b441f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies <- knn_results |> \n",
    "       filter(.metric == \"accuracy\")\n",
    "\n",
    "accuracy_versus_k <- ggplot(accuracies, aes(x = neighbors, y = mean))+\n",
    "       geom_point() +\n",
    "       geom_line() +\n",
    "       labs(x = \"Neighbors\", y = \"Accuracy Estimate\") +\n",
    "       ggtitle(\"Accuracy vs. K\") +\n",
    "       theme(text = element_text(size = 20))\n",
    "accuracy_versus_k"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c175223-e80b-4e90-afd3-b872e2bbff7a",
   "metadata": {},
   "source": [
    "Based on the above plot, we see that the accuracy decreases quite steeply as the number of neighbors increases, before leveling off from around K = 16 onwards. We choose K = 17 for our classification model because the accuracy is high at this point, and the accuracy does not change drastically when looking at similar K values. Overall, we want to avoid overfitting the data by selecting too few neighbors, and 17 is an odd number (given that K-nearest neighbors classifies observations based on a majority rules system, using an even number of neighbors could be problematic in the event of a tie, since our class variable is binary). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94cc5c8-f7b7-462b-9dc3-ad4d81cdd5de",
   "metadata": {},
   "source": [
    "Upon determining the optimal K value for our classifier, we can finally predict on our testing set. As done below, we use the same recipe as before, but a new model that sets the number of neighbors to 17 must be built. Once we have used the model to predict the classes of the observations in the test set, we take a confusion matrix to view the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8248be-dd71-44eb-bc6a-cc64a680de11",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_spec_final <- nearest_neighbor(weight_func = \"rectangular\", neighbors = 17) |>\n",
    "                    set_engine(\"kknn\") |>\n",
    "                    set_mode(\"classification\")\n",
    "\n",
    "pulsar_fit_final <- workflow() |>\n",
    "        add_recipe(pulsar_recipe) |>\n",
    "        add_model(knn_spec_final) |>\n",
    "        fit(data = pulsar_train)\n",
    "\n",
    "pulsar_test_predictions_final <-  predict(pulsar_fit_final, pulsar_test) |>\n",
    "        bind_cols(pulsar_test)\n",
    "\n",
    "pulsar_test_predictions_final                \n",
    "\n",
    "confusion_final <- pulsar_test_predictions_final |>\n",
    "    conf_mat(truth = class, estimate = .pred_class)\n",
    "confusion_final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80337786-6d08-450c-8231-061bc18bf298",
   "metadata": {},
   "source": [
    "To visualize the accuracy of our classification model, we create a new column in the predictions table that will allow us to visualze the test data in such a way that colour-coding the observations will let us see the information stored in the confusion matrix. (***not worded very well)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ab16dc-0121-4492-b614-091faa0061ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "mutated_predictions <- pulsar_test_predictions_final |>\n",
    "    mutate(new_cat = case_when(.pred_class == 0 & class == 0 ~ \"False pulsar, correctly classified\",\n",
    "                               .pred_class == 1 & class == 1 ~ \"Real pulsar, correctly classified\",\n",
    "                               .pred_class == 1 & class == 0 ~ \"False pulsar, incorrectly classified\",\n",
    "                               .pred_class == 0 & class == 1 ~ \"Real pulsar, incorrectly classified\"))\n",
    "mutated_predictions\n",
    "\n",
    "#this code came from: https://community.rstudio.com/t/creating-a-new-variable-under-conditions-of-other-two-variables/51825 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd50700-bf7e-4cf7-a342-d02cb65b0153",
   "metadata": {},
   "source": [
    "<b> Visualization: Classifier accuracy </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab9c464-84ad-4a16-b9c8-855c6d16031f",
   "metadata": {},
   "outputs": [],
   "source": [
    "options(repr.plot.height = 10, repr.plot.width = 14)\n",
    "\n",
    "#First 2 predictors\n",
    "plot_1 <- ggplot() +\n",
    "    geom_point(data = mutated_predictions, mapping = aes(x = exc_kurtosis_integrated_profile, \n",
    "                                                              y = mean_dmsnr, colour = new_cat), alpha = 0.5) +\n",
    "    labs(x = \"Scaled Excess Kurtosis - Integrated Profile\", y = \"Scaled Mean - DMSNR curve\", colour = \"Prediction\") +\n",
    "    ggtitle(\"Classifier accuracy with regards to mean of DMSNR\n",
    "                \\ncurve and excess kurtosis of integrated profile\") +\n",
    "    scale_color_brewer(palette = \"Dark2\") +\n",
    "    theme(text = element_text(size = 20))\n",
    "plot_1\n",
    "\n",
    "\n",
    "\n",
    "#Next 2 predictors\n",
    "plot_2 <- ggplot() +\n",
    "    geom_point(data = mutated_predictions, mapping = aes(x = skew_dmsnr,\n",
    "                                                              y = skew_integrated_profile, colour = new_cat), alpha = 0.5) +\n",
    "    labs(x = \"Scaled Skewness - DMSNR curve\", y = \"Scaled Skewness - Integrated Profile\", colour = \"Prediction\") +\n",
    "    ggtitle(\"Classifier accuracy with regards to skewkness\n",
    "                \\nof both DMSNR curve and integrated profile\") +\n",
    "    scale_color_brewer(palette = \"Dark2\") +\n",
    "    theme(text = element_text(size = 20))\n",
    "plot_2\n",
    "\n",
    "\n",
    "\n",
    "#Last 2 predictors\n",
    "plot_3 <- ggplot() +\n",
    "    geom_point(data = mutated_predictions, mapping = aes(x = stand_dev_integrated_profile, \n",
    "                                                             y = exc_kurtosis_dmsnr, colour = new_cat), alpha = 0.5) +\n",
    "    labs(x = \"Scaled Standard Deviation - Integrated Profile\", y = \"Scaled Excess Kurtosis - DMSNR curve\", colour = \"Prediction\") +\n",
    "    ggtitle(\"Classifier accuracy with regards to excess kurtosis of\n",
    "                \\nDMSNR curve and standard deviation of integrated profile\") +\n",
    "    scale_color_brewer(palette = \"Dark2\") +\n",
    "    theme(text = element_text(size = 20))\n",
    "plot_3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511f40e0-0a1a-4b35-862c-f6e1cab7a207",
   "metadata": {},
   "source": [
    "As can be seen above, there are very few observations in the testing set that were incorrectly classified. This indicates that our model is quite accurate. We can represent the accuracy of our model as a percentage, as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2d99de-ed02-480e-8fc3-0e92d18fed0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#From the confusion matrix:\n",
    "\n",
    "accuracy_perc <- ((3838 + 3853)/8130)*100\n",
    "accuracy_perc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0cce850-d0c1-4a2b-a29a-0d4c27d51260",
   "metadata": {},
   "source": [
    "Therefore, <b> ~95% </b> is a good estimate of how accuracte our classication model is."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e75e84a-fc2f-4ad1-9499-4b7f7bed1fed",
   "metadata": {},
   "source": [
    "<b>Discussion </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b8cada9-9701-4662-b305-866fa4825139",
   "metadata": {},
   "source": [
    "summarize what you found: We found that training a classifier with our predictors (name them*) yields the most accurate predictions on new observations (i.e. the testing set). The accuracy of our model is __.\n",
    "\n",
    "discuss whether this is what you expected to find?\n",
    "- Personally, before upsampling I wasn’t expecting a really high prediction accuracy with any combination of predictors, due to how rare the real pulsars were in the original dataset\n",
    "- Also, I don’t think I was expecting that the most accurate classifier would come from using 6 of the 8 variables available to us in the dataset → in our class readings it was mentioned that using very few or many predictors often harms how good the classifier is at making predictions (would have expected between 2-4 predictors to give the highest accuracy)\n",
    "\n",
    "discuss what impact could such findings have?\n",
    "\n",
    "discuss what future questions could this lead to?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c5f4b5-a704-4ce1-bf06-579b54b9f3b8",
   "metadata": {},
   "source": [
    "**References**\n",
    "\n",
    "Dr Robert Lyon, University of Manchester, School of Physics and Astronomy, Alan Turing Building, Manchester M13 9PL, United Kingdom, robert.lyon '@' manchester.ac.uk\n",
    "\n",
    "Keith, M. J., et al. (2010). The HTRU survey. Handbook of pulsar astronomy, 379-422.\n",
    "\n",
    "United States. National Aeronautics and Space Administration. NASA technical note. Washington :National Aeronautics and Space Administration.\n",
    "\n",
    "Paula, G. (2020, February 5). Creating a new variable under conditions of other two variables. Posit Community. Retrieved April 13, 2023, from https://community.rstudio.com/t/creating-a-new-variable-under-conditions-of-other-two-variables/51825  \n",
    "\n",
    "do we need to cite the textbook?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10af3ded-fe1b-4137-8f5b-d18d0a90f2ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.1.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
